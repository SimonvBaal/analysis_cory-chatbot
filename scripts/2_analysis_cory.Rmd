---
title: "Cory - analysis"
author: "Simon van Baal"
date: "16/02/2022"
output: html_document
---

```{r setup, include=FALSE}

library(readr)
library(dplyr)
library(here)
library(ordinal)
library(ordinalCont)
library(finalfit)
library(afex)
library(emmeans)
library(onewaytests)
library(rcompanion)


```

```{r load data, include=FALSE}

surveyData <- 
  read_csv(here("data/clean/clean_surveys_cory.csv"))
chatbotData <- 
  read_csv(here("data/clean/clean_chatbot_cory.csv"))

```

## Descriptive statistics

In this section, we start by providing some descriptive statistics about the sample, in addition to providing information about the distribution of the variables of interest.

```{r Descriptive statistics}

# Here we gather descriptive statistics by sex
surveyData |>
  group_by(ParticipantID, Sex, Age) |>
  summarise(n = n()) |>
  group_by(Sex) |>
  summarise(meanAge = mean(as.numeric(Age), na.rm = T),
            sdAge = sd(as.numeric(Age), na.rm = T),
            n = n())

# Some nationality data if needed
surveyData |>
  group_by(Nationality) |>
  summarise(n = n())

# Group level statistics on the perceived importance of testing
surveyData |>
  group_by(Timepoint, Condition) |>
  summarise(TestImportance = mean(TestImportance)) |>
  arrange(Condition, desc(Timepoint))

surveyData |>
  group_by(Condition, ParticipantID) |>
  tally() |>
  group_by(Condition) |>
  tally()

# Group level statistics about the intention to get tested if the participant detects symptoms.
chatbotData |>
  group_by(Condition, testingLikelihood) |>
  summarise(n = n())
```

```{r missing-data-analysis}
dependentVar <- 
  "testingLikelihood"
independentVar <-
  c("Condition", "Sex", "Age")

chatbotData |>
  missing_pattern(dependentVar, independentVar)

missPlotTestLikelihood <- 
  chatbotData |>
  missing_plot(dependentVar, independentVar)

chatbotData |>
  missing_pairs(dependentVar, independentVar)

chatbotData |>
  group_by(testingLikelihood) |>
  mutate(testingLikelihood = ifelse(is.na(testingLikelihood), 
                                          "missing", 
                                          "not missing")) |>
  summarise(meanAge = round(mean(Age, na.rm = T), 1))

chatbotData |>
  group_by(testingLikelihood, Essential) |>
  mutate(testingLikelihood = ifelse(is.na(testingLikelihood), 
                                          "missing", 
                                          "not missing")) |>
  tally() |>
  filter(!is.na(Essential))

#18/34*100 
#9/24*100

chatbotData |>
  group_by(testingLikelihood, Sex) |>
  mutate(testingLikelihood = ifelse(is.na(testingLikelihood), 
                                          "missing", 
                                          "not missing")) |>
  tally() |>
  filter(!is.na(Sex))

# missing female 23, 11
# non-missing female 17, 7

surveyData |> 
  group_by(Timepoint, ParticipantID, Age, Sex) |>
  tally() |>
  group_by(ParticipantID, Age, Sex) |>
  tally() |>
  arrange(n, ParticipantID) |>
  group_by(n, Sex) |>
  filter(!is.na(Sex)) |>
  tally()

# 7/10 female for missing surveys
# 32/45 female for non-missing surveys

# Ages of groups with and without missing data in surveys
surveyData |> 
  group_by(Timepoint, ParticipantID, Age) |>
  tally() |>
  group_by(ParticipantID, Age) |>
  tally() |>
  arrange(n, ParticipantID) |>
  group_by(n) |>
  filter(!is.na(Age)) |>
  summarise(meanAge = mean(Age))

surveyData |> 
  group_by(Timepoint, ParticipantID, Essential) |>
  tally() |>
  group_by(ParticipantID, Essential) |>
  tally() |>
  arrange(n, ParticipantID) |>
  group_by(n, Essential) |>
  filter(!is.na(Essential)) |>
  tally()

```



## Getting Tested when Experiencing COVID-19 Symptoms

Here we analyse whether the behavioural interventions and the interaction with the chatbot influenced people's likelihood of getting tested, and their perceived importance of getting tested.

```{r Analysis prep CLM}

# Ordering factor levels and scaling the age variable.
chatbotData <-
  chatbotData |>
  mutate(
    testingLikelihood = factor(
      testingLikelihood,
      levels = c("Very Unlikely",
                 "I don't know",
                 "Very Likely")
    ),
    testingLikNum = ifelse(
      testingLikelihood ==
        "Very Unlikely",
      1,
      ifelse(
        testingLikelihood ==
          "I don't know",
        2,
        ifelse(testingLikelihood ==
                 "Very Likely", 3, NA)
      )
    ),
    Condition = factor(
      Condition,
      levels = c("Control",
                 "Compassion",
                 "Exponential Growth")
    ),
    Age = scale(Age, center = T, scale = T),
    Sex = factor(Sex)
  )


# Set contrasts for factor to sum contrasts
contrasts(chatbotData$Condition) <- contr.sum(3)
contrasts(chatbotData$Sex) <- contr.sum(2)

```


```{r Cumulative Link Model testing likelihood}

# Run cumulative link model

clmTestingLikelihood <- 
  clm(testingLikelihood ~ 
        Condition +
        Sex +
        Age,
       data = chatbotData |> 
        filter(!is.na(testingLikelihood)),
      link = "logit")
# Hessian singular -> collapse categories (done above).

chiSqTestClm <- drop1(clmTestingLikelihood, test = "Chi")

# # Due to convergence issues, pairwise tests are not done through the model with emmeans
# emmeansClmTestingLikelihood <- 
#   emmeans(clmTestingLikelihood, specs = "Condition", mode = "mean.class")
# pairs(emmeansClmTestingLikelihood, reverse = T)


# Instead, we conduct simple Mann-Whitney U tests.
wTestExp <-
  wilcox.test(
    x = chatbotData$testingLikNum[chatbotData$Condition == 
                                    "Exponential Growth"],
    y = chatbotData$testingLikNum[chatbotData$Condition == 
                                    "Control"],
    paired = F,
    exact = F,
    conf.int = T,
    alternative = "greater"
  )

wTestComp <-
  wilcox.test(
    x = chatbotData$testingLikNum[chatbotData$Condition ==
                                    "Compassion"],
    y = chatbotData$testingLikNum[chatbotData$Condition ==
                                    "Control"],
    paired = F,
    exact = F,
    conf.int = T,
    alternative = "greater"
  )

ZValueWTestExp <-
  wilcoxonZ(
    x = chatbotData$testingLikNum[chatbotData$Condition == 
                                    "Exponential Growth"],
    y = chatbotData$testingLikNum[chatbotData$Condition == 
                                    "Control"],
    paired = F,
    exact = F,
    digits = 4
  )

zValueWTestComp <-
  wilcoxonZ(
    x = chatbotData$testingLikNum[chatbotData$Condition ==
                                    "Compassion"],
    y = chatbotData$testingLikNum[chatbotData$Condition ==
                                    "Control"],
    paired = F,
    exact = F,
    digits = 4
  )

adjustedPvalues <- p.adjust(c(.028, .20), method = "BH")



```

## Importance of Testing for COVID-19

Here we analyse whether the chatbot increases the perceived importance of testing as part of the public health response.

```{r Testing importance}

# Testing importance of getting tested before and after Cory.
testImportanceData <-
  surveyData |>
  group_by(ParticipantID, Sex, Age, Timepoint, Condition) |>
  summarise(testImportance = mean(TestImportance)) |>
  pivot_wider(
    id_cols = c("ParticipantID", "Sex", "Age", "Condition"),
    names_from = "Timepoint",
    values_from = "testImportance"
  ) |>
  mutate(
    testImportanceDifference = `Post-Test` - `Pre-Test`,
    Condition = factor(
      Condition,
      levels = c("Control",
                 "Exponential Growth",
                 "Compassion")
    ),
    Sex = factor(Sex)
  ) |>
  filter(!is.na(testImportanceDifference),
         !is.na(Sex))

contrasts(testImportanceData$Sex) <- contr.sum(2)

testImportanceData |>
  group_by(Condition) |>
  summarise(mean = mean(testImportanceDifference),
            sd = sd(testImportanceDifference))

```


```{r modelling perceived importance of testing}

ocmFullModelTestImportance <-
  ocm(testImportanceDifference ~
        Condition +
        Sex +
        Age,
        data = testImportanceData)

ocmReducedTestImportance <-
  ocm(testImportanceDifference ~
        Sex +
        Age,
      data = testImportanceData)

anova(ocmFullModelTestImportance, ocmReducedTestImportance)

# Effects:
#                              Estimate    StdErr t.value  p.value   
# ConditionExponential Growth  0.056070  0.625981  0.0896 0.930082   
# ConditionCompassion         -2.381093  0.735830 -3.2359 0.007005 **

ciLowerImportanceExp = .056070 - 1.96*.625981
ciUpperImportanceExp = .056070 + 1.96*.625981

ciLowerImportanceComp = -2.381093 - 1.96*.735830
ciUpperImportanceComp = -2.381093 + 1.96*.735830

adjustedPvaluesTestImp <- p.adjust(c(.007, .92), method = "BH")

```

## Attitudes to Going Out

Here we analyse whether Cory influenced people's judgments of whether it is acceptable to leave the house or not in various scenarios.


```{r Certainty analysis prep}
# Add absolute value for certainty about going out.

surveyData <- 
  surveyData |>
  mutate(AbsCertainty = abs(Attitude),
         scaledAge = scale(Age),
         Sex = factor(Sex),
         Timepoint = factor(Timepoint, 
                            levels = c("Pre-Test", 
                                       "Post-Test")))

contrasts(surveyData$Sex) <- contr.sum(2)

```

We conduct likelihood ratio tests to determine the best combination of the two variables of interest: Timepoint and Risk, where the two control variables Age and Sex remain in the model in each iteration.
The first test is whether the full model, with an interaction of risk level and timepoint, is the best model. Then we see whether each of these variables on their own constitute a significant improvement of the model.
```{r Certainty Likelihood Ratio Tests}
# Full model

ocmFullModelCertainty <-
  ocm(
    AbsCertainty ~
      Risk * Timepoint +
      Age +
      Sex +
      (1 | ParticipantID),
    surveyData |>
      filter(!is.na(Age))
  )

# Reduced models

ocmReduced1Certainty <-
  ocm(
    AbsCertainty ~
      Risk + Timepoint +
      Age +
      Sex +
      (1 | ParticipantID),
    surveyData |>
      filter(!is.na(Age))
  )

ocmReduced2Certainty <-
  ocm(AbsCertainty ~
        Risk +
        Age +
        Sex +
        (1 | ParticipantID),
      surveyData |>
        filter(!is.na(Age)))

ocmReduced3Certainty <-
  ocm(AbsCertainty ~
        Timepoint +
        Age +
        Sex +
        (1 | ParticipantID),
      surveyData |>
        filter(!is.na(Age)))

# Likelihood ratio tests

lrtCertainty <-
  anova(ocmFullModelCertainty,
        ocmReduced1Certainty,
        ocmReduced2Certainty,
        ocmReduced3Certainty)

# Now test for inclusion of the risk factor when time-point is in the model

lrtCertainty2 <-
  anova(ocmReduced1Certainty,
        ocmReduced3Certainty)

```


```{r Cont ordinal - attitudes to going out: pairwise - high risk attitudes}
# Now we estimate models with different reference levels in order to do pairwise
# comparisons.

surveyData |>
  filter(!is.na(Age)) |>
  group_by(Timepoint) |>
  summarise(mean = mean(AbsCertainty),
            sd = sd(AbsCertainty))


# High Risk, Post-Test is the reference point here 
# (because of alphabetical ordering)
ocm1Certainty <- 
  ocm(AbsCertainty ~ 
          Risk*Timepoint + 
        Age +
        Sex +
          (1|ParticipantID),
         surveyData |> 
        filter(!is.na(Age)))

# Here the difference between pre-test and post-test in high risk scenarios is:
#                               Estimate    StdErr t.value   p.value
#TimepointPost-Test              0.042846  0.128981  0.3322 0.7406793 

ciLowerTimepointHigh = 0.042846 - 0.128981 * 1.96
ciUpperTimepointHigh = 0.042846 + 0.128981 * 1.96

surveyData |>
  filter(!is.na(Age), Risk == "High") |>
  group_by(Timepoint) |>
  summarise(mean = mean(AbsCertainty),
            sd = sd(AbsCertainty))

```



```{r Low risk attitudes}

# we do the same for low risk scenarios
surveyData <-
  surveyData |>
  mutate(Risk = factor(Risk, levels = c("Low", "High", "Minimal")))

# Now we run the model with low risk as the reference level.
ocm2Certainty <- 
  ocm(AbsCertainty ~ 
          Risk*Timepoint + 
        Age +
        Sex +
          (1|ParticipantID),
         surveyData |> 
        filter(!is.na(Age)))

# Here the difference between pre-test and post-test in low risk scenarios is:
#                               Estimate    StdErr t.value   p.value
#TimepointPost-Test             -0.832905  0.182084 -4.5743 1.862e-05 ***

ciLowerTimepointLow = -0.832905 - 0.182084 * 1.96
ciUpperTimepointLow = -0.832905 + 0.182084 * 1.96
surveyData |>
  filter(!is.na(Age), Risk == "Low") |>
  group_by(Timepoint) |>
  summarise(mean = mean(AbsCertainty),
            sd = sd(AbsCertainty))

```



```{r Minimal risk attitudes}

# And now for minimal risk attitudes

surveyData <-
  surveyData |>
  mutate(Risk = factor(Risk, levels = c("Minimal", "Low", "High")))

ocm3Certainty <- 
  ocm(AbsCertainty ~ 
          Risk*Timepoint + 
        Age +
        Sex +
          (1|ParticipantID),
         surveyData |> 
        filter(!is.na(Age)))

# Here the difference between pre-test and post-test in minimal risk scenarios is:
#                            Estimate    StdErr t.value   p.value
#TimepointPost-Test          -1.206200  0.194421 -6.2041 2.799e-08 ***

ciLowerTimepointMinimal = -1.206200 - 0.194421 * 1.96
ciUpperTimepointMinimal = -1.206200 + 0.194421 * 1.96
surveyData |>
  filter(!is.na(Age), Risk == "Minimal") |>
  group_by(Timepoint) |>
  summarise(mean = mean(AbsCertainty),
            sd = sd(AbsCertainty))

```



```{r Certainty main effects analysis}
# For main effects we sequentially introduce sum contrasts.

# Set sum contrasts for risk, so we may evaluate the main effect of Timepoint.
contrasts(surveyData$Risk) <- contr.sum(3)

ocmMainTimepointCertainty <- 
  ocm(AbsCertainty ~ 
          Risk*Timepoint + 
        Age +
        Sex +
          (1|ParticipantID),
         surveyData |> 
        filter(!is.na(Age)))
# The main effect of timepoint is:
#                          Estimate    StdErr t.value   p.value
#TimepointPost-Test       -0.665420  0.101618 -6.5482 6.544e-09 ***
ciLowerTimepointMain = -0.665420 - 0.101618 * 1.96
ciUpperTimepointMain = -0.665420 +  0.101618 * 1.96

surveyData |>
  filter(!is.na(Age)) |>
  group_by(Timepoint) |>
  summarise(mean = mean(AbsCertainty),
            sd = sd(AbsCertainty))

# Set Risk back to treatment contrasts, and set Timepoint to sum contrasts,
# if you would like to evaluate the main effect of risk.
contrasts(surveyData$Risk) <- contr.treatment(3)
contrasts(surveyData$Timepoint) <- contr.sum(2)

ocmMainRiskCertainty <- 
  ocm(AbsCertainty ~ 
          Risk*Timepoint + 
        Age +
        Sex +
          (1|ParticipantID),
         surveyData |> 
        filter(!is.na(Age)))
```

